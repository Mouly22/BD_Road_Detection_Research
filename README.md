In the realm of advancing transportation systems, understanding visual environments is pivotal for autonomous vehicle deployment. This project delves into training YOLOv5 and YOLOv8 models on the RSUD20k dataset, detecting various vehicles from images. Achieving promising results after extensive training, we extend our exploration by enhancing augmentation techniques. From Random Horizontal Flipping to Photometric Distortions, we meticulously analyze the impact of each enhancement on model performance. By testing on unseen images, we bridge the gap between simulation and real-world application. This GitHub repository serves as a comprehensive resource, offering insights and methodologies for traffic pattern analysis and autonomous vehicle development.

The following link gives an overview regarding the project including our research topic, main goal, working methodoligies and obstacles we plan to overcome : [Click Here](https://www.canva.com/design/DAGDZv3PvIc/7FbT-g4kBgzCrcVG3K-SVQ/view?utm_content=DAGDZv3PvIc&utm_campaign=designshare&utm_medium=link&utm_source=editor)

The dataset we are using for this research: [RSUD20K](https://www.kaggle.com/datasets/hasibzunair/rsud20k-bangladesh-road-scene-understanding/data)

Our project report regarding the research: [Overleaf](https://www.overleaf.com/read/sdfdnhxzzxdx#04d050)  <div align=""> <img src="https://user-images.githubusercontent.com/74038190/235223599-0eadbd7c-c916-4f24-af9d-9242730e6172.gif" width="75">&nbsp;  </div>





